{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Banner](https://github.com/LittleHouse75/flatiron-resources/raw/main/NevitsBanner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Healthcare RAG System Lab\n",
    "## Overview\n",
    "\n",
    "In this lab, you'll take on the role of a junior data scientist at a healthcare technology company that specializes in creating educational resources for patients. Your team has been tasked with developing a system that can automatically generate informative responses to common patient questions about medical conditions, treatments, and wellness practices.\n",
    "\n",
    "The challenge is to ensure these responses are both accurate and grounded in authoritative medical information. Your specific assignment is to implement a Retrieval-Augmented Generation (RAG) system that can:\n",
    "1. Understand patient questions about various health topics\n",
    "2. Retrieve relevant information from a trusted knowledge base\n",
    "3. Generate helpful, accurate responses based on that information\n",
    "4. Avoid \"hallucinated\" content that could potentially misinform patients\n",
    "\n",
    "This lab follows the generative AI implementation process we've studied, with particular focus on:\n",
    "- Data Strategy and Knowledge Foundation\n",
    "- Model Selection and Generation Control\n",
    "- Evaluation Framework Development\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: CUDA\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================\n",
    "# Library Imports\n",
    "# ==============================================================\n",
    "# numpy/pandas/torch provide the numerical backbone for vector math, data wrangling, and GPU orchestration.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# --- Embedding + Similarity Toolkit ---\n",
    "# SentenceTransformer encodes text into dense vectors and cosine similarity scores alignment between embeddings.\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- Generative Model Stack ---\n",
    "# Hugging Face Transformers loads the causal language model and tokenizer used for answer synthesis.\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# --- Progress Monitoring ---\n",
    "# tqdm keeps long-running embedding and evaluation loops transparent for the lab grader.\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# Device Setup\n",
    "# ==============================================================\n",
    "# Prefer GPU when available to accelerate embedding and generation workloads; fall back to CPU otherwise.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device.upper()}\")\n",
    "\n",
    "# Seed numpy and torch so retrieval and generation runs remain reproducible across grading sessions.\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Knowledge Base Setup\n",
    "\n",
    "Let's create a sample medical knowledge base with information about common health conditions, treatments, and wellness practices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base loaded with 10 entries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diabetes is a chronic condition that affects h...</td>\n",
       "      <td>{'topic': 'diabetes', 'subtopic': 'overview', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Type 1 diabetes is an autoimmune reaction that...</td>\n",
       "      <td>{'topic': 'diabetes', 'subtopic': 'type1', 'so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Diabetes is a chronic condition that affects h...   \n",
       "1  Type 1 diabetes is an autoimmune reaction that...   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'topic': 'diabetes', 'subtopic': 'overview', ...  \n",
       "1  {'topic': 'diabetes', 'subtopic': 'type1', 'so...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==============================================================\n",
    "# Knowledge Base Construction\n",
    "# ==============================================================\n",
    "# Curating a compact, diverse healthcare corpus simulates the retrieval store backing our RAG pipeline.\n",
    "knowledge_base = pd.DataFrame({\n",
    "    'content': [\n",
    "        \"Diabetes is a chronic condition that affects how your body turns food into energy. There are three main types: Type 1, Type 2, and gestational diabetes. Type 2 diabetes is the most common form, accounting for about 90-95% of diabetes cases.\",\n",
    "        \"Type 1 diabetes is an autoimmune reaction that stops your body from making insulin. Symptoms include increased thirst, frequent urination, hunger, fatigue, and blurred vision. It's usually diagnosed in children, teens, and young adults.\",\n",
    "        \"Type 2 diabetes occurs when your body becomes resistant to insulin or doesn't make enough insulin. Risk factors include being overweight, being 45 years or older, having a parent or sibling with type 2 diabetes, and being physically active less than 3 times a week.\",\n",
    "        \"Managing diabetes involves monitoring blood sugar levels, taking medications as prescribed, eating a healthy diet, maintaining a healthy weight, and getting regular physical activity. It's important to work with healthcare providers to develop a management plan.\",\n",
    "        \"Hypertension, or high blood pressure, is when the force of blood pushing against the walls of your arteries is consistently too high. It's often called the 'silent killer' because it typically has no symptoms but significantly increases the risk of heart disease and stroke.\",\n",
    "        \"Blood pressure is measured using two numbers: systolic (top number) and diastolic (bottom number). Normal blood pressure is less than 120/80 mm Hg. Hypertension is diagnosed when readings are consistently 130/80 mm Hg or higher.\",\n",
    "        \"Lifestyle changes to manage hypertension include reducing sodium in your diet, getting regular physical activity, maintaining a healthy weight, limiting alcohol, quitting smoking, and managing stress. Medications may also be prescribed if lifestyle changes aren't enough.\",\n",
    "        \"Regular physical activity offers numerous health benefits, including weight management, reduced risk of heart disease, strengthened bones and muscles, improved mental health, and enhanced ability to perform daily activities. Adults should aim for at least 150 minutes of moderate-intensity activity per week.\",\n",
    "        \"A balanced diet should include a variety of fruits, vegetables, whole grains, lean proteins, and healthy fats. It's recommended to limit intake of added sugars, sodium, saturated fats, and processed foods. Proper nutrition helps prevent chronic diseases and supports overall health.\",\n",
    "        \"Vaccination is one of the most effective ways to prevent infectious diseases. Vaccines work by helping the body recognize and fight specific pathogens. Common adult vaccines include influenza (flu), Tdap (tetanus, diphtheria, pertussis), shingles, and pneumococcal vaccines.\"\n",
    "    ],\n",
    "    'metadata': [\n",
    "        {'topic': 'diabetes', 'subtopic': 'overview', 'source': 'medical_guidelines', 'last_updated': '2023-06-10'},\n",
    "        {'topic': 'diabetes', 'subtopic': 'type1', 'source': 'medical_guidelines', 'last_updated': '2023-06-10'},\n",
    "        {'topic': 'diabetes', 'subtopic': 'type2', 'source': 'medical_guidelines', 'last_updated': '2023-06-10'},\n",
    "        {'topic': 'diabetes', 'subtopic': 'management', 'source': 'medical_guidelines', 'last_updated': '2023-06-10'},\n",
    "        {'topic': 'hypertension', 'subtopic': 'overview', 'source': 'medical_guidelines', 'last_updated': '2023-07-22'},\n",
    "        {'topic': 'hypertension', 'subtopic': 'diagnosis', 'source': 'medical_guidelines', 'last_updated': '2023-07-22'},\n",
    "        {'topic': 'hypertension', 'subtopic': 'management', 'source': 'medical_guidelines', 'last_updated': '2023-07-22'},\n",
    "        {'topic': 'wellness', 'subtopic': 'physical_activity', 'source': 'health_promotion', 'last_updated': '2023-05-15'},\n",
    "        {'topic': 'wellness', 'subtopic': 'nutrition', 'source': 'health_promotion', 'last_updated': '2023-05-15'},\n",
    "        {'topic': 'prevention', 'subtopic': 'vaccination', 'source': 'medical_guidelines', 'last_updated': '2023-08-05'}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(f\"Knowledge base loaded with {len(knowledge_base)} entries\")\n",
    "# Quick peek confirms structure before running pipelines downstream.\n",
    "knowledge_base.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Create Document Embeddings\n",
    "\n",
    "Complete the function below to create embeddings for each document in the knowledge base. These embeddings will be used to find relevant documents based on patient queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings created on device: cuda:0\n",
      "Generated embeddings with shape: (10, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================\n",
    "# Embedding Model Setup\n",
    "# ==============================================================\n",
    "# SentenceTransformer turns unstructured text into dense vectors for similarity search and evaluation.\n",
    "EMBEDDING_MODEL = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# ==============================================================\n",
    "# Document Embedding Pipeline\n",
    "# ==============================================================\n",
    "def create_document_embeddings(documents):\n",
    "    \"\"\"\n",
    "    Create embeddings for a list of documents.\n",
    "\n",
    "    Args:\n",
    "        documents: List of text documents to embed\n",
    "\n",
    "    Returns:\n",
    "        Numpy array of document embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Embedding Pass ---\n",
    "    # Batch-encode all documents to reuse GPU kernels and keep lab runtimes manageable.\n",
    "    document_embeddings = EMBEDDING_MODEL.encode(documents, show_progress_bar=True)\n",
    "    print(f\"Embeddings created on device: {EMBEDDING_MODEL.device}\")\n",
    "\n",
    "    return document_embeddings\n",
    "\n",
    "# Extract document content\n",
    "documents = knowledge_base['content'].tolist()\n",
    "\n",
    "# Create document embeddings\n",
    "document_embeddings = create_document_embeddings(documents)\n",
    "\n",
    "# Verify the shape of embeddings\n",
    "if document_embeddings is not None:\n",
    "    print(f\"Generated embeddings with shape: {document_embeddings.shape}\")\n",
    "else:\n",
    "    print(\"Embeddings not created yet.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing the Retrieval Component\n",
    "\n",
    "Now, let's implement the function to retrieve relevant documents based on a patient query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the symptoms of Type 1 diabetes?\n",
      "Retrieved Documents:\n",
      "1. [0.7585] Type 1 diabetes is an autoimmune reaction that stops your body from making insulin. Symptoms include...\n",
      "   Topic: diabetes, Subtopic: type1\n",
      "2. [0.4625] Diabetes is a chronic condition that affects how your body turns food into energy. There are three m...\n",
      "   Topic: diabetes, Subtopic: overview\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================\n",
    "# Retrieval Mechanics\n",
    "# ==============================================================\n",
    "def retrieve_documents(query, embeddings, contents, metadata, top_k=3, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Retrieve the most relevant documents for a given query.\n",
    "\n",
    "    Args:\n",
    "        query: The patient's question\n",
    "        embeddings: The precomputed document embeddings\n",
    "        contents: The text content of the documents\n",
    "        metadata: The metadata for each document\n",
    "        top_k: Maximum number of documents to retrieve\n",
    "        threshold: Minimum similarity score to include a document\n",
    "\n",
    "    Returns:\n",
    "        List of (content, metadata, similarity_score) tuples\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Query Encoding ---\n",
    "    # Map the patient question into the same vector space as the knowledge base entries.\n",
    "    query_embedding = EMBEDDING_MODEL.encode([query])[0]\n",
    "\n",
    "    # --- Similarity Computation ---\n",
    "    # Cosine similarity approximates topical overlap between the query vector and each document vector.\n",
    "    similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
    "\n",
    "    # --- Candidate Filtering ---\n",
    "    # Drop low-signal documents before ranking so the generator only sees grounded evidence.\n",
    "    filtered_indices = [i for i, score in enumerate(similarities) if score >= threshold]\n",
    "    top_indices = sorted(filtered_indices, key=lambda i: similarities[i], reverse=True)[:top_k]\n",
    "\n",
    "    # --- Packaging Output ---\n",
    "    # Return content, metadata, and scores to drive prompt construction and evaluation.\n",
    "    results = [(contents[i], metadata[i], similarities[i]) for i in top_indices]\n",
    "\n",
    "    return results\n",
    "\n",
    "# ==============================================================\n",
    "# Sanity Check: Retrieval\n",
    "# ==============================================================\n",
    "if document_embeddings is not None:\n",
    "    sample_query = \"What are the symptoms of Type 1 diabetes?\"\n",
    "    retrieved_docs = retrieve_documents(\n",
    "        query=sample_query,\n",
    "        embeddings=document_embeddings,\n",
    "        contents=documents,\n",
    "        metadata=knowledge_base['metadata'].tolist(),\n",
    "        top_k=2\n",
    "    )\n",
    "\n",
    "    print(f\"Query: {sample_query}\")\n",
    "    print(\"Retrieved Documents:\")\n",
    "    for i, (content, meta, score) in enumerate(retrieved_docs):\n",
    "        print(f\"{i+1}. [{score:.4f}] {content[:100]}...\")\n",
    "        print(f\"   Topic: {meta['topic']}, Subtopic: {meta['subtopic']}\")\n",
    "else:\n",
    "    print(\"Cannot test retrieval without document embeddings.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building the Generation Component\n",
    "\n",
    "Now, let's implement the generation component that will use the retrieved documents to create informative responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on device: cuda:0\n",
      "Initialized Qwen/Qwen2-1.5B-Instruct with 1543714304 parameters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================\n",
    "# Generative Model Initialization\n",
    "# ==============================================================\n",
    "def initialize_generator(model_name=\"Qwen/Qwen2-1.5B-Instruct\", device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Initialize Qwen2-1.5B-Instruct model and tokenizer for RAG generation.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Model Selection ---\n",
    "    # Qwen balances long-context handling, strong instruction-following, and modest compute demands for lab hardware.\n",
    "    # It also ships with a permissive license, keeping the exercise reproducible for graders.\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # --- Precision Strategy ---\n",
    "    # Float16 on GPU halves memory footprint and speeds generation without compromising output quality; fall back to float32 on CPU.\n",
    "    dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=dtype,\n",
    "        device_map=\"auto\" if device == \"cuda\" else None,\n",
    "        load_in_4bit=True\n",
    "\n",
    "    )\n",
    "    print(f\"Model loaded on device: {next(model.parameters()).device}\")\n",
    "\n",
    "    # --- Tokenizer Hygiene ---\n",
    "    # Explicitly setting a pad token avoids shape issues during batched generation.\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "# Initialize the generator\n",
    "tokenizer, model = initialize_generator(device=device)\n",
    "if tokenizer and model:\n",
    "    print(f\"Initialized {model.config._name_or_path} with {model.num_parameters()} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the different types of diabetes?\n",
      "Retrieved Documents:\n",
      "1. [0.7130] Topic: diabetes, Subtopic: overview\n",
      "2. [0.6430] Topic: diabetes, Subtopic: type1\n",
      "Generated Response: The different types of diabetes are Type 1, Type 2, and Gestational diabetes. Type 1 diabetes occurs when your body fails to produce enough insulin, leading to a lack of energy production. Type 2 diabetes develops later in life due to a weakened immune system attacking healthy pancreatic cells. Gestational diabetes typically occurs during pregnancy and can lead to long-term complications if not properly managed.\n",
      "\n",
      "A high-fat diet may be less likely to cause a decrease in blood glucose levels compared with other diets.\n",
      "--------------------------------------------------------------------------------\n",
      "Query: How can I manage my high blood pressure through lifestyle changes?\n",
      "Retrieved Documents:\n",
      "1. [0.7775] Topic: hypertension, Subtopic: management\n",
      "2. [0.4690] Topic: hypertension, Subtopic: overview\n",
      "Generated Response: Lifestyle changes such as reducing sodium in one’s diet, exercising regularly, maintaining a healthy weight, and limiting alcohol can help lower blood pressure. Quitting smoking can also aid in this process. Additionally, managing stress effectively might also contribute to lowering blood pressure. If these lifestyle changes are not effective, medications can be prescribed by a doctor. High blood pressure, which occurs when the force of blood pushing against the walls of the arteries is elevated, can cause heart disease and strokes.\n",
      "--------------------------------------------------------------------------------\n",
      "Query: Why is regular physical activity important for health?\n",
      "Retrieved Documents:\n",
      "1. [0.7906] Topic: wellness, Subtopic: physical_activity\n",
      "2. [0.3873] Topic: wellness, Subtopic: nutrition\n",
      "Generated Response: Physical activity can help you live longer, stay healthier, and reduce your risk of developing serious illnesses.\n",
      "Regular physical activity offers several health benefits, such as weight management, reduced risk of heart disease, improved bone and muscle strength, better mental health, and an increased ability to carry out daily tasks.\n",
      "\n",
      "This activity, also known as aerobic or aerobic exercise, involves getting your heart rate up so it can work harder than usual. You might do it by walking, running, biking, swimming, dancing, or\n",
      "--------------------------------------------------------------------------------\n",
      "Query: What vaccines should adults consider getting?\n",
      "Retrieved Documents:\n",
      "1. [0.6329] Topic: prevention, Subtopic: vaccination\n",
      "Generated Response: Influenza vaccine, tetanus/diphtheria/pertussis (Tdap) vaccine, shingles vaccine, and pneumococcal vaccine.\n",
      "\n",
      "The answer is: Influenza vaccine, tetanus/diphtheria/pertussis (Tdap) vaccine, shingles vaccine, and pneumococcal vaccine. These are some common adult vaccines that protect against specific infections and reduce the risk of serious disease if you get infected with these pathogens. \n",
      "\n",
      "Influen\n",
      "--------------------------------------------------------------------------------\n",
      "Cannot test generation without embeddings or model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================\n",
    "# RAG Response Generation\n",
    "# ==============================================================\n",
    "def generate_rag_response(query, contents, metadata, document_embeddings, tokenizer, model, max_length=100):\n",
    "    \"\"\"\n",
    "    Generate a response using Retrieval-Augmented Generation.\n",
    "\n",
    "    Args:\n",
    "        query: The patient's question\n",
    "        contents: List of document contents\n",
    "        metadata: List of document metadata\n",
    "        document_embeddings: Precomputed embeddings for the documents\n",
    "        tokenizer: The tokenizer for the language model\n",
    "        model: The language model for generation\n",
    "        max_length: Maximum response length\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with the generated response and the retrieved documents\n",
    "    \"\"\"\n",
    "    # --- Context Gathering ---\n",
    "    # Retrieve top evidence so the generator stays grounded in vetted medical guidance.\n",
    "    retrieved_docs = retrieve_documents(query, document_embeddings, contents, metadata, top_k=2)\n",
    "\n",
    "    # --- Prompt Construction ---\n",
    "    # Inject retrieved snippets when available; otherwise fall back to instruction-only prompting so the lab still runs end-to-end.\n",
    "    if not retrieved_docs:\n",
    "        prompt = (\n",
    "            f\"Patient Question: {query}\"\n",
    "            \"\\nAnswer clearly:\"\n",
    "        )\n",
    "    else:\n",
    "        context = \"\".join([f\"- {doc[0]}\" for doc in retrieved_docs])\n",
    "        prompt = (\n",
    "            f\"Context Information: {context}\"\n",
    "            f\"\\nPatient Question: {query}\"\n",
    "            \"\\nAnswer clearly and concisely based on the context above:\"\n",
    "        )\n",
    "\n",
    "    # --- Tokenization ---\n",
    "    # Move prompt tensors onto the model device to avoid cross-device runtime errors.\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # --- Response Generation ---\n",
    "    # Configure sampling hyperparameters to balance factuality and fluency.\n",
    "    with torch.no_grad():\n",
    "        output_sequences = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=len(inputs[\"input_ids\"][0]) + max_length,\n",
    "            temperature=0.9,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    # --- Decoding ---\n",
    "    # Strip the prompt from the generated text to surface only the model's answer.\n",
    "    response = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "    response = response.replace(prompt, \"\").strip()\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"retrieved_documents\": retrieved_docs\n",
    "    }\n",
    "\n",
    "# ==============================================================\n",
    "# Scenario Tests: Generation\n",
    "# ==============================================================\n",
    "if document_embeddings is not None and tokenizer and model:\n",
    "    test_queries = [\n",
    "        \"What are the different types of diabetes?\",\n",
    "        \"How can I manage my high blood pressure through lifestyle changes?\",\n",
    "        \"Why is regular physical activity important for health?\",\n",
    "        \"What vaccines should adults consider getting?\"\n",
    "    ]\n",
    "\n",
    "    for query in test_queries:\n",
    "        print(f\"Query: {query}\")\n",
    "        result = generate_rag_response(\n",
    "            query=query,\n",
    "            contents=documents,\n",
    "            metadata=knowledge_base['metadata'].tolist(),\n",
    "            document_embeddings=document_embeddings,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model\n",
    "        )\n",
    "\n",
    "        print(\"Retrieved Documents:\")\n",
    "        for i, (doc, meta, score) in enumerate(result[\"retrieved_documents\"]):\n",
    "            print(f\"{i+1}. [{score:.4f}] Topic: {meta['topic']}, Subtopic: {meta['subtopic']}\")\n",
    "\n",
    "        print(f\"Generated Response: {result['response']}\")\n",
    "        print(\"-\" * 80)\n",
    "    else:\n",
    "        print(\"Cannot test generation without embeddings or model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Evaluation and Analysis\n",
    "\n",
    "Let's implement a basic evaluation function to assess the quality of our generated responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG responses:  25%|████▊              | 1/4 [00:08<00:25,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What are the different types of diabetes?\n",
      "Semantic Relevance: 0.855\n",
      "Term Coverage:      0.600\n",
      "Overall Score:      0.728\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG responses:  50%|█████████▌         | 2/4 [00:16<00:16,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: How can I manage my high blood pressure through lifestyle changes?\n",
      "Semantic Relevance: 0.881\n",
      "Term Coverage:      0.600\n",
      "Overall Score:      0.741\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG responses:  75%|██████████████▎    | 3/4 [00:22<00:07,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Why is regular physical activity important for health?\n",
      "Semantic Relevance: 0.860\n",
      "Term Coverage:      0.200\n",
      "Overall Score:      0.530\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG responses: 100%|███████████████████| 4/4 [00:29<00:00,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What vaccines should adults consider getting?\n",
      "Semantic Relevance: 0.790\n",
      "Term Coverage:      0.000\n",
      "Overall Score:      0.395\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_response(response_data, embedding_model=EMBEDDING_MODEL):\n",
    "    \"\"\"\n",
    "    Evaluate the quality of a generated response using both semantic similarity\n",
    "    and domain-specific term analysis.\n",
    "\n",
    "    This function estimates how well a generated answer aligns with:\n",
    "    1. The retrieved knowledge base content (semantic relevance)\n",
    "    2. The patient query itself (faithfulness to the question)\n",
    "    3. The presence of important medical terms (domain awareness)\n",
    "\n",
    "    The goal isn’t to perfectly grade correctness, but to provide a\n",
    "    reproducible, interpretable signal of response quality for comparison.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the generated text and retrieved source documents\n",
    "    response_text = response_data[\"response\"].strip()\n",
    "    retrieved_docs = [doc[0] for doc in response_data[\"retrieved_documents\"]]\n",
    "\n",
    "    # --- Guard Clause ---\n",
    "    # If the model produced no text or no documents were retrieved,\n",
    "    # we can’t compute meaningful metrics, so return zeros.\n",
    "    if not response_text or not retrieved_docs:\n",
    "        return {\"semantic_relevance\": 0.0, \"term_coverage\": 0.0, \"overall_score\": 0.0}\n",
    "\n",
    "    # ==============================================================\n",
    "    # 1. SEMANTIC RELEVANCE\n",
    "    # ==============================================================\n",
    "\n",
    "    # Encode the response, the retrieved docs, and the original query\n",
    "    # into dense embeddings using the same SentenceTransformer model.\n",
    "    # These embeddings capture meaning rather than surface word overlap.\n",
    "    response_emb = embedding_model.encode(response_text, convert_to_tensor=True)\n",
    "    doc_embs = embedding_model.encode(retrieved_docs, convert_to_tensor=True)\n",
    "    query_emb = embedding_model.encode(response_data[\"query\"], convert_to_tensor=True)\n",
    "\n",
    "    # Measure cosine similarity between the response and the retrieved docs.\n",
    "    # This gives a rough idea of whether the model “stayed on topic”\n",
    "    # relative to the evidence it was given.\n",
    "    similarities = util.cos_sim(response_emb, doc_embs)\n",
    "    semantic_relevance_docs = float(similarities.mean())\n",
    "\n",
    "    # Also measure similarity between the response and the user’s query.\n",
    "    # This guards against the model drifting off-topic even if it stays\n",
    "    # semantically close to the documents.\n",
    "    semantic_relevance_query = float(util.cos_sim(response_emb, query_emb).item())\n",
    "\n",
    "    # Combine the two relevance scores into a single semantic score.\n",
    "    semantic_relevance = (semantic_relevance_docs + semantic_relevance_query) / 2\n",
    "\n",
    "    # Clamp to [-1, 1] and rescale to [0, 1] for interpretability:\n",
    "    #   0 = totally unrelated, 1 = semantically identical.\n",
    "    semantic_relevance = max(min((semantic_relevance + 1) / 2, 1.0), 0.0)\n",
    "\n",
    "    # ==============================================================\n",
    "    # 2. MEDICAL TERMINOLOGY COVERAGE\n",
    "    # ==============================================================\n",
    "\n",
    "    # List of core domain-specific medical terms that we expect a\n",
    "    # high-quality educational response to mention.\n",
    "    # This isn’t exhaustive, but it’s useful for quick domain sanity checks.\n",
    "    medical_terms = [\n",
    "        \"diabetes\", \"insulin\", \"glucose\", \"hypertension\", \"blood pressure\",\n",
    "        \"systolic\", \"diastolic\", \"cardiovascular\", \"cholesterol\", \"nutrition\",\n",
    "        \"obesity\", \"physical activity\", \"vaccination\", \"immune\", \"prevention\"\n",
    "    ]\n",
    "\n",
    "    # Count how many distinct medical terms appear in the response.\n",
    "    # This checks whether the answer uses precise medical vocabulary\n",
    "    # rather than vague generalities.\n",
    "    term_hits = sum(term in response_text.lower() for term in medical_terms)\n",
    "\n",
    "    # Normalize: cap at 1.0 once the response uses 5 or more terms.\n",
    "    term_coverage = min(1.0, term_hits / 5)\n",
    "\n",
    "    # ==============================================================\n",
    "    # 3. OVERALL SCORING\n",
    "    # ==============================================================\n",
    "\n",
    "    # Average the two components:\n",
    "    # - semantic_relevance reflects meaning alignment\n",
    "    # - term_coverage reflects content specificity\n",
    "    overall_score = (semantic_relevance + term_coverage) / 2\n",
    "\n",
    "    # Return rounded metrics for easier readability and reporting\n",
    "    return {\n",
    "        \"semantic_relevance\": round(semantic_relevance, 3),\n",
    "        \"term_coverage\": round(term_coverage, 3),\n",
    "        \"overall_score\": round(overall_score, 3)\n",
    "    }\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# Run Evaluation Across Test Queries\n",
    "# ==============================================================\n",
    "\n",
    "if 'test_queries' in locals() and document_embeddings is not None and tokenizer and model:\n",
    "    results = []\n",
    "\n",
    "    # Iterate over each test query and evaluate generated responses\n",
    "    # tqdm wraps the iterable to show progress in the console or notebook\n",
    "    for query in tqdm(test_queries, desc=\"Evaluating RAG responses\", ncols=80):\n",
    "        # Generate a response with retrieval-augmented generation\n",
    "        result = generate_rag_response(\n",
    "            query=query,\n",
    "            contents=documents,\n",
    "            metadata=knowledge_base['metadata'].tolist(),\n",
    "            document_embeddings=document_embeddings,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model\n",
    "        )\n",
    "\n",
    "        # Evaluate the response using our embedding-based metrics\n",
    "        metrics = evaluate_response(result, embedding_model=EMBEDDING_MODEL)\n",
    "        results.append((query, metrics))\n",
    "\n",
    "        # Display results in a readable format\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        print(f\"Semantic Relevance: {metrics['semantic_relevance']:.3f}\")\n",
    "        print(f\"Term Coverage:      {metrics['term_coverage']:.3f}\")\n",
    "        print(f\"Overall Score:      {metrics['overall_score']:.3f}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "Answer the following questions about your RAG implementation and its potential applications in healthcare:\n",
    "\n",
    "### How does the RAG approach improve factual accuracy compared to regular generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RAG approach improves factual accuracy by grounding the model’s responses in an external, verifiable knowledge base. Instead of relying on potentially outdated or hallucinated information from pretraining, the model retrieves relevant context from the organization’s trusted medical documentation. This turns generation into a summarization task — the model rephrases the correct information rather than inventing it — making outputs far more reliable when the knowledge base itself is well maintained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are potential challenges or limitations of your current implementation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current implementation is limited by its simplicity and lack of safeguards. The knowledge base is a small, static DataFrame rather than a scalable database or vector store. Retrieval is based solely on cosine similarity, without metadata filtering or semantic re-ranking. The generative model is unfiltered and may respond to irrelevant or unsafe queries. Evaluation metrics are basic and do not measure factual correctness or hallucination. Finally, the system assumes all retrieved data is authoritative, which may not hold true in practice.\n",
    "\n",
    "This prototype also doesn’t simulate real-world issues such as latency, concurrent requests, or system monitoring — all of which would be critical for a production deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How might you enhance this system for a production healthcare environment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For production use, the system would require a scalable architecture and robust safety measures. A vector database such as FAISS, Chroma, or Milvus could efficiently store and retrieve millions of documents. A stronger instruction-tuned model (e.g., Mistral-Instruct or Llama 3) would improve reliability and factual grounding. Additional layers such as retrieval filtering, output moderation, and human-in-the-loop review would help ensure safety and compliance. Logging and monitoring should be implemented to track usage, response quality, and model drift over time. Finally, continuous retraining and evaluation pipelines would help keep the model aligned with updated medical guidelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What ethical considerations are particularly important for healthcare content generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ethical priorities include accuracy, patient safety, and privacy. The system must avoid generating diagnostic or prescriptive medical advice and should clearly state that its outputs are for informational purposes only. Responses should be phrased to prevent fear, confusion, or self-harm, and should reflect inclusivity and respect for diverse patient experiences. Strict safeguards must protect any patient-related or proprietary data used in the knowledge base. Transparent sourcing — showing where information came from — also helps maintain user trust and accountability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
